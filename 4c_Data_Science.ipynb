{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Python Programming\n",
    "\n",
    "[**CC-BY-NC-SA**](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)<br/>\n",
    "Prof. Dr. Annemarie Friedrich<br/>\n",
    "with some minor edits by Dr. Jakob Prange<br/>\n",
    "Faculty of Applied Computer Science, University of Augsburg<br/>\n",
    "\n",
    "## 4c Python for Data Science\n",
    "\n",
    "Data Science is, roughly speaking, the field of applying tools from mathematics, statistics, artificial intelligence, and computer engineering for extracting knowledge from data. Python is the preferred programming and scripting language for data scientists. IPython and Jupyter notebooks are a common form to perform a data analysis, mixing code, textual information, and visualization.\n",
    "\n",
    "The goal of this lecture is to become familiar with the basics of common data science toolkits (NumPy, Pandas, Matplotlib, and (to a limited extent) Scikit-Learn).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 NumPy\n",
    "\n",
    "NumPy (Numerical Python) is a library for the efficient stoarge and manipulation of numerical arrays. It also includes a suite of mathematical computing tools. You can find the documentation of NumPy [here](https://numpy.org/doc/stable/reference/).\n",
    "\n",
    "At the core of NumPy is the `array` class, which can be used to store vectors, matrices, or even tensors (higher-dimensional data).\n",
    "We can create `array` objects in a number of ways, the simplest of which is to instantiate it from a list.\n",
    "In th example below, `a.shape` returns the tuple `(6,)`, which tells us that `a` is a vectors with six entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is common to import NumPy like this:\n",
    "import numpy as np\n",
    "\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 34, 4, 3, 2, 5.6])\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next example, we instantiate a NumPy `array` with a two-dimensional list, i.e., `m` is a matrix of shape `(2, 3)`, i.e., it has two rows and three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1, 2, 3], [3, 4, 5]])\n",
    "pp.pprint(m)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more complicated, in the next example, we create a tensor of shape `(4, 2, 3)`, which means that it consists of four matrices of shape `(2, 3)` each. We can visualize such cases in three-dimensional space (see slides).\n",
    "\n",
    "Exercise: Try out what `t.ndim` prints and look up in the documentation what it means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[[1, 1, 1], [1, 1, 1]], [[2, 2, 2], [2, 2, 2]], [[3, 3, 3], [3, 3, 3]], [[4, 4, 4], [4, 4, 4]]])\n",
    "pp.pprint(t)\n",
    "print(\"t.shape =\", t.shape)\n",
    "# t.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to Python lists, the entries of a NumPy `array` must all have the same datatype. By default, this will be the datatype that covers all entries, e.g., in the case `[1.2, 4, 2]`, NumPy will create an object with `float32` types. We can also specify the datatype for an array explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3], dtype=\"float32\")\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Broadcasting__\n",
    "\n",
    "An important concept to understand when performing calculations with NumPy is that of __broadcasting__.\n",
    "The following code accompanies the examples and rules illustrated in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting\n",
    "M = np.ones((2, 3))\n",
    "a = np.arange(3)\n",
    "pp.pprint(M)\n",
    "pp.pprint(a)\n",
    "pp.pprint(a+M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Masks__\n",
    "\n",
    "Masking is a useful tool when it comes to extracting, modifying, or counting particular values in a NumPy `array`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0, 8, 6, 2], [0, -1, 3, 0]])\n",
    "print(\"x =\")\n",
    "pp.pprint(x)\n",
    "\n",
    "# Mask\n",
    "print(\"\\nx != 0 at these positions:\")\n",
    "pp.pprint(x != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask `x != 0` returns a matrix of the exact same size as `x`, with entries being `True` is the respective value in `x` is unequal `0`, and `False` otherwise. Next, we use this mask (a) to count how many non-zero items `x` contains, and  (b) to retrieve particular values from `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) counting non-zero items\n",
    "mask = x != 0\n",
    "pp.pprint(mask)\n",
    "print(np.sum(mask)) # counts the True values in mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) retrieving items\n",
    "y = x[x != 0]\n",
    "print(\"y =\")\n",
    "pp.pprint(y) # Note that this returns a vector of those values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform operations such as `sum` row-wise or column-wise. It may at first be a bit confusing _which_ axis the summation is performed over in the following case, so let's examine this step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x =\")\n",
    "pp.pprint(x)\n",
    "print(x.shape)\n",
    "# summing row-wise: we \"generalize\" over columsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2, 4)` means there are two rows and 4 columns, i.e., dimension `0` corresponds to the rows and dimension `1` to the columns.\n",
    "Let's sum over rows, and over columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(x)\n",
    "row_sums = np.sum(x, axis=1) # axis=1: \"generalize\" over columns / \"removing\" this dimension by the operation\n",
    "print(\"row_sums:\", row_sums)\n",
    "\n",
    "col_sums = np.sum(x, axis=0) # axis=0: \"generalize\" over rows / \"removing\" this dimension by the operation\n",
    "print(\"col_sums:\", col_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check carefully that you understand this principle. (If you move on to deep learning, for example, the same principle is followed by PyTorch.) In the general case, the `axis` that you specify is that over which the operation generalizes and which, as a result, gets removed by the operation. This also holds if we have more than two dimensions.\n",
    "\n",
    "Next, let's combine the summing operation with a mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many values less than 6 in each row?\n",
    "print(np.sum(x < 6, axis=1)) # axis=1: \"generalize\" over columns\n",
    "print(np.sum(x < 6, axis=0)) # axis=0: \"generalize\" over rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Numpy Exercises__:\n",
    "\n",
    "1. Find out how to create a matrix of `(n,m)` zeros or ones easily.\n",
    "\n",
    "2. Find out (and note for yourself) the differences between `ndim`, `shape`, and `size`.\n",
    "\n",
    "3. Use the `np.reshape()` function to create matrices and tensors of various sizes from the vector `x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])`. Note down the general functionality of `np.reshape()`.\n",
    "\n",
    "4. Find out how to `concatenate` two vectors. Next, find out how to stack them vertically into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Pandas\n",
    "\n",
    "Pandas is a library offering convenient storage for labeled and heterogenous data. It is built on top of NumPY and also provides powerful data operations similar to database or spreadsheet operations. You can find the API references of Pandas [here](https://pandas.pydata.org/docs/reference/index.html).\n",
    "\n",
    "One basic type in Pandas is `Series`, which consists of entries that are each associated with an item in an index (similar to a dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is common to import Pandas like this:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_list = [4.5, 1.3, 2.7, 2.3]\n",
    "grade_series = pd.Series(grade_list)\n",
    "print(grade_series)\n",
    "\n",
    "grade_dict = {\"Susie\":4.5, \"Tim\":1.3, \"Lucie\":2.7, \"Frank\":2.3}\n",
    "grade_series = pd.Series(grade_dict)\n",
    "grade_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the `Index` object like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second important datatype is `DataFrame`, which is similar to a spreadsheet or database table. A `DataFrame` is a two-dimensional array, or a sequence of __named__ (see column name!) and __aligned__ (as indicated by their index values) `Series` objects. The indices of the `Series` objects must match.\n",
    "\n",
    "We can simply create a `DataFrame` object from dictionaries as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_grades = [4.0, 2.5, 1.3, 2.7]\n",
    "python_grades = [3.0, 1.3, 2.0, 3.0]\n",
    "names = [\"Susie\", \"Tim\", \"Tom\", \"Lisa\"]\n",
    "\n",
    "df = pd.DataFrame({\"Name\" : names, \"Math\": math_grades, \"Python\": python_grades})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing a `DataFrame` object from a dictionary as above, Pandas assumes that the dictionary keys are the column names and the lists that are the dictionary values are the row-wise entries. In this case, a numeric index `[0, 1, 2, 3]` is constructed automatically (you can see it in the left-most column, which is not a named `Series` but just the `Index`).\n",
    "\n",
    "Often, the data is already available in spreadsheet format, or, as in the following case, as a CSV file. Luckily, Pandas provides a number of `read` methods that can read in tabular data from various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in grades and additional information from CSV file\n",
    "df = pd.read_csv(\"data/grades.csv\", delimiter=\" \")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pandas Exercises__\n",
    "\n",
    "_Check out the Pandas API reference to solve the following exercises._\n",
    "\n",
    "1. Which of [these formats](https://pandas.pydata.org/docs/reference/io.html) do you know already?\n",
    "2. Make sure you understand the output of the method `describe()` (API see [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)).\n",
    "3. Sort the table by \"Grade\", and assign the sorted `DataFrame` object to the variable `df`. What happened to the index?\n",
    "4. Use `loc` to retrieve and print the entry for index `2`.\n",
    "5. Assume we want to create an anonymous statistic of class attendance and grade. Use `loc` to retrieve the two relevant columns. (Hint: see [here](https://pandas.pydata.org/docs/user_guide/10min.html#selection),  \"Selection by label.\")\n",
    "6. Using `loc`, retrieve the Grade for the entry with index `1`. Do the same using `at`. Find out what the difference between the two functions is.\n",
    "7. What is the difference between `df.loc[1]` and `df.iloc[1]`? (Hint: try this on our sorted `DataFrame` object from above to see the effect.) Read on these two methods to access data in the API reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to NumPy, we can also use __Masking__ with Pandas `DataFrame`s.\n",
    "The following example illustrates how to find a row with a particular cell value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/grades.csv\", delimiter=\" \")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we obtain a mask indicating for each index value, whether the condition that the cell value of the column \"Firstname\" is \"Lucie\" applies. This is a pointer to rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[\"Firstname\"] == \"Lucie\") # Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this Mask to obtain the relevant row from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[df[\"Firstname\"] == \"Lucie\"]) # obtain relevant row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df[\"Firstname\"] == \"Lucie\"] # assign this view to another variable\n",
    "print(df2[\"Grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to:\n",
    "print(\"Grade of Lucie\", df[df[\"Firstname\"] == \"Lucie\"][\"Grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make clear how the mask works, consider the following extension of the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending another row to the dataframe\n",
    "new_row = {\"Firstname\":\"Lucie\", \"Lastname\":\"Lucky\", \"ClassAttendance\":1.0, \"HomeworkCompleted\":0.9, \"Grade\":1.0}\n",
    "df.loc[len(df)] = new_row  # len(df) is the new index: here it is simple as we have a numeric integer-range based index\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucie_subset = df[df[\"Firstname\"] == \"Lucie\"]\n",
    "display(lucie_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we have selected all rows where the condition that the Firstname is Lucie applies. If we select the grade now, we get both the grades of the two Lucies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lucie_subset[\"Grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also provides database-like operations such as `groupby`. The following code first groups the entries of the dataframe by the value of a particular column, and then applies an operation group-wise.\n",
    "\n",
    "In the following example, Tim and Susie are playing a game. Each has three trials, in which a certain number of blue and a certain number of red points are achieved. The objective of the game is to obtain as many blue points as possible, and as few red points as possible. For each of these objectives, the best result out of the three trials counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\"Name\" : [\"Tim\", \"Tim\", \"Tim\", \"Susie\", \"Susie\", \"Susie\"],\n",
    "      \"BluePoints\" : [1, 5, 3, 8, 2, 1],\n",
    "      \"RedPoints\" : [4, 5, 2, 1, 2, 3]})\n",
    "\n",
    "display(df3)\n",
    "\n",
    "print(\"Game Results (best of trials):\")\n",
    "print(type(df3.groupby(\"Name\"))) # This is a DataFrameGroupBy object. We can perform, for example, aggregation operations on it as follows:\n",
    "results = df3.groupby(\"Name\").agg({\"BluePoints\": \"max\", \"RedPoints\" : \"min\"})\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final number of points is computed by taking the number of blue points minus that of the red points. Who won the game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with final scores\n",
    "results[\"FinalScore\"] = results[\"BluePoints\"] - results[\"RedPoints\"]\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have worked through the basics of NumPy and Pandas. Let's now visualize the data.<br/><br/>\n",
    "\n",
    "### 13.3 Matplotlib\n",
    "\n",
    "Matplotlib is a well-tested, cross-platform visualization and plotting library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import Matplotlib like this:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's draw a __scatterplot__ to see if there is any correlation between class attendance and grade and between homework completion in the grade in our tiny class example above.\n",
    "Plotting a scatterplot is very easy in Matplotlib, we just need to tell it what the `x` and `y` values are.\n",
    "There is also a function called `scatter`, but the `plot` is more faster when used with many datapoints.\n",
    "The first argument of `plot` below are the `x`-values, the second are the `y`-values, and the third argument indicates the style of the plotting: here, we give just the strings `s` and `o`, which indicate the type of marker to be drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df[\"ClassAttendance\"]*100 # converting to percent (happens entry-wise!)\n",
    "y1 = df[\"Grade\"]\n",
    "plt.plot(x1, y1, 'o', color='blue', markersize=10, label=\"ClassAttendance\")\n",
    "\n",
    "x2 = df[\"HomeworkCompleted\"]*100 # converting to percent (happens entry-wise!)\n",
    "y2 = df[\"Grade\"]\n",
    "plt.plot(x2, y2, 's', color='red', markersize=10, label=\"HomeworkCompleted\") # s=square\n",
    "\n",
    "# Let's add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Let's add axis labels\n",
    "plt.xlabel(\"Percent\")\n",
    "plt.ylabel(\"Grade\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voil√†! What can we read from this scatterplot?\n",
    "\n",
    "Often, it is useful to check the data using __histogram__ plots. A histogram tells us how many instances fall into a particular bin. Let's look at the following example to illustrate this.\n",
    "\n",
    "Assume we walk around for a month and measure everyone whom we meet. We record their height and gender, and have the following dataset in the end. (The data is completely made up!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [\"m\"]*100 + [\"f\"]*100 + [\"d\"]*100\n",
    "m_heights = np.minimum(np.random.normal(1.9, 0.1, 100), [2.3]*100)\n",
    "f_heights = np.minimum(np.random.normal(1.55, 0.1, 100), [2.0]*100)\n",
    "d_heights = np.minimum(np.random.normal(1.7, 0.1, 100), [2.1]*100)\n",
    "heights = np.concatenate((m_heights, f_heights, d_heights))\n",
    "\n",
    "df = pd.DataFrame({\"Gender\" : gender, \"BodyHeight\" : heights})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"BodyHeight\"], bins=30) # Try out varying number of bins\n",
    "plt.ylabel(\"Number of measured people with this size\")\n",
    "plt.xlabel(\"Height in m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a full example, let us create one histogram per gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(alpha=0.5, bins=20) # Keyword arguments that we will reuse for each histogram\n",
    "# **kwargs \"unfolds\" the dictionary into its key-value pairs as they are required as arguments.\n",
    "# alpha=0.5 indicates the transparency (try out other values)\n",
    "\n",
    "plt.hist(df[df[\"Gender\"] == \"m\"][\"BodyHeight\"], **kwargs, label=\"m\")\n",
    "plt.hist(df[df[\"Gender\"] == \"f\"][\"BodyHeight\"], **kwargs, label=\"f\")\n",
    "plt.hist(df[df[\"Gender\"] == \"d\"][\"BodyHeight\"], **kwargs, label=\"d\")\n",
    "plt.ylabel(\"Number of measured people with this size\")\n",
    "plt.xlabel(\"Height in m\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matplotlib (& Pandas) Exercise__\n",
    "\n",
    "In this exercise, your task is to visualize the label distribution of the paragraphs in the [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus). The dataset consists of a set of texts taken from 15 categories.\n",
    "\n",
    "You may have to refer to the API references of Matplotlib to solve this exercise. Make sure you understand the code.\n",
    "\n",
    "1. From the provided dataframe, get the list of categories.\n",
    "2. For each category, count how many paragraphs (i.e., rows) are in the dataframe.\n",
    "3. Create a barplot showing for each category, how many instances there are.\n",
    "4. Rotate the `xticks` such that they are vertical.\n",
    "5. Add labels to the `x` and `y` axes stating \"category\" and \"number of instances.\"\n",
    "6. Add labels to each bar stating the number of instances of the respective category.\n",
    "7. If you followed the steps above, the labels of the bars probably overlap. Find out how to make the plot wider such that it looks nice.\n",
    "8. Finally, increase the font size of the `xlabel` and the `ylabel` and add a title to your plot (e.g., \"Brown Corpus Category Distribution for Paragraphs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/brown.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
